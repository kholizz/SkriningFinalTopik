{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Summarization - (tf-idf)\n",
    "\n",
    "#### STEP 1 : Data cleaning \n",
    "#### STEP 2 : Score of sentences (tf-idf)\n",
    "#### STEP 3 : Summary Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Phase\n",
    "### Importing Libraries and Reading Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### importing the necessary libraries\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import pandas\n",
    "import nltk\n",
    "import re\n",
    "# from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('../Data/articles.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    A small airplane crashed into a government bui...\n",
      "1    Witnesses reported hearing a loud explosion wh...\n",
      "2    Italian authorities confirmed that a small air...\n",
      "3    Automatic text summarization aims to reduce a ...\n",
      "4    Centroid-based summarization represents docume...\n",
      "5    Word embeddings allow semantic comparison betw...\n",
      "Name: text, dtype: object\n",
      "415\n",
      "310\n",
      "280\n",
      "305\n",
      "262\n",
      "242\n"
     ]
    }
   ],
   "source": [
    "print(df['text'])\n",
    "\n",
    "for a in df['text']:\n",
    "    print(len(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing sentences into words which would be used for calculating tf-idf scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### tokenized the sentences from the different news articles\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "s = \"\"\n",
    "for a in df['text']:\n",
    "      s += a\n",
    "sentences = sent_tokenize(s)\n",
    "# sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 1 : Data Cleaning\n",
    "### Cleaning sentences, by removing Non Alphabet Characters and converting to Lower Case Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a small airplane crashed into a government building in the heart of milan  setting the top floors on fire italian police reported that there were no immediate reports of casualties rescue workers attempted to clear the area in the city s financial district the incident caused fears of a possible terrorist attack similar to september    emergency services rushed to the scene and investigations were initiated witnesses reported hearing a loud explosion when a small aircraft struck a    story office building near milan s central train station smoke was seen pouring from the upper floors of the building police and ambulances responded quickly authorities stated that the cause of the crash was under investigation italian authorities confirmed that a small airplane accidentally crashed into an office building in milan the building houses regional government offices no terrorism link was confirmed firefighters managed to control the fire while emergency responders evacuated nearby areas automatic text summarization aims to reduce a document into a shorter version while preserving the most important information extractive summarization selects important sentences from the original text recent approaches utilize word embeddings to capture semantic similarity between words and sentences centroid based summarization represents documents using vector representations word embeddings improve traditional tf idf by capturing semantic relationships sentences close to the semantic centroid are selected as summaries  improving coherence and relevance word embeddings allow semantic comparison between sentences beyond surface word matching combining centroid based methods with embeddings enhances summarization performance  especially for documents with varied vocabulary and writing styles '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### pre processes the sentences by removing non alphabet characters and converting them to lower case letters \n",
    "### and stored in variable text\n",
    "\n",
    "dict = {}\n",
    "text=\"\"\n",
    "for a in sentences:\n",
    "    temp = re.sub(\"[^a-zA-Z]\",\" \",a)\n",
    "    temp = temp.lower()\n",
    "    dict[temp] = a\n",
    "    text+=temp\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 2 : Getting tf-idf score of sentences\n",
    "### Finding term frequency ( tf ) of words found in text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'small': 3, 'airplane': 2, 'crashed': 2, 'government': 2, 'building': 5, 'heart': 1, 'milan': 3, 'setting': 1, 'top': 1, 'floors': 2, 'fire': 2, 'italian': 2, 'police': 2, 'reported': 2, 'immediate': 1, 'reports': 1, 'casualties': 1, 'rescue': 1, 'workers': 1, 'attempted': 1, 'clear': 1, 'area': 1, 'city': 1, 'financial': 1, 'district': 1, 'incident': 1, 'caused': 1, 'fears': 1, 'possible': 1, 'terrorist': 1, 'attack': 1, 'similar': 1, 'september': 1, 'emergency': 2, 'services': 1, 'rushed': 1, 'scene': 1, 'investigations': 1, 'initiated': 1, 'witnesses': 1, 'hearing': 1, 'loud': 1, 'explosion': 1, 'aircraft': 1, 'struck': 1, 'story': 1, 'office': 2, 'near': 1, 'central': 1, 'train': 1, 'station': 1, 'smoke': 1, 'seen': 1, 'pouring': 1, 'upper': 1, 'ambulances': 1, 'responded': 1, 'quickly': 1, 'authorities': 2, 'stated': 1, 'cause': 1, 'crash': 1, 'investigation': 1, 'confirmed': 2, 'accidentally': 1, 'houses': 1, 'regional': 1, 'offices': 1, 'terrorism': 1, 'link': 1, 'firefighters': 1, 'managed': 1, 'control': 1, 'responders': 1, 'evacuated': 1, 'nearby': 1, 'areas': 1, 'automatic': 1, 'text': 2, 'summarization': 4, 'aims': 1, 'reduce': 1, 'document': 1, 'shorter': 1, 'version': 1, 'preserving': 1, 'important': 2, 'information': 1, 'extractive': 1, 'selects': 1, 'sentences': 4, 'original': 1, 'recent': 1, 'approaches': 1, 'utilize': 1, 'word': 4, 'embeddings': 4, 'capture': 1, 'semantic': 4, 'similarity': 1, 'words': 1, 'centroid': 3, 'based': 2, 'represents': 1, 'documents': 2, 'using': 1, 'vector': 1, 'representations': 1, 'improve': 1, 'traditional': 1, 'tf': 1, 'idf': 1, 'capturing': 1, 'relationships': 1, 'close': 1, 'selected': 1, 'summaries': 1, 'improving': 1, 'coherence': 1, 'relevance': 1, 'allow': 1, 'comparison': 1, 'beyond': 1, 'surface': 1, 'matching': 1, 'combining': 1, 'methods': 1, 'enhances': 1, 'performance': 1, 'especially': 1, 'varied': 1, 'vocabulary': 1, 'writing': 1, 'styles': 1}\n"
     ]
    }
   ],
   "source": [
    "### calculated the frequency of the words found in text\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "word_frequencies = {}\n",
    "for word in nltk.word_tokenize(text):\n",
    "    if word not in stopwords:\n",
    "        if word not in word_frequencies.keys():\n",
    "            word_frequencies[word] = 1\n",
    "        else:\n",
    "            word_frequencies[word] += 1\n",
    "print (word_frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding weighted frequency of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### finding weighted frequency of the words\n",
    "\n",
    "max_freq = max(word_frequencies.values())\n",
    "\n",
    "for w in word_frequencies :\n",
    "      word_frequencies[w]/=max_freq\n",
    "# print word_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating sentence scores from the word frequncies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculating sentence scores from the word frequncies\n",
    "\n",
    "sentence_scores = {}\n",
    "for sent in sentences:\n",
    "    for word in nltk.word_tokenize(sent.lower()):\n",
    "        if word in word_frequencies.keys():\n",
    "            if len(sent.split(' ')) < 30:\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_frequencies[word]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_frequencies[word]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 3 : Summary Generation\n",
    "### Outputting the top 17 sentences as the summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### getting the summary by taking top score sentences\n",
    "\n",
    "import heapq\n",
    "summary_sentences = heapq.nlargest(17, sentence_scores, key=sentence_scores.get)\n",
    "summary = ' '.join(summary_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sentences close to the semantic centroid are selected as summaries, improving coherence and relevance.Word embeddings allow semantic comparison between sentences beyond surface word matching.',\n",
       " 'Emergency services rushed to the scene and investigations were initiated.Witnesses reported hearing a loud explosion when a small aircraft struck a 30-story office building near Milan’s central train station.',\n",
       " 'Recent approaches utilize word embeddings to capture semantic similarity between words and sentences.Centroid-based summarization represents documents using vector representations.',\n",
       " 'Authorities stated that the cause of the crash was under investigation.Italian authorities confirmed that a small airplane accidentally crashed into an office building in Milan.',\n",
       " 'Firefighters managed to control the fire while emergency responders evacuated nearby areas.Automatic text summarization aims to reduce a document into a shorter version while preserving the most important information.',\n",
       " 'A small airplane crashed into a government building in the heart of Milan, setting the top floors on fire.',\n",
       " 'Combining centroid-based methods with embeddings enhances summarization performance, especially for documents with varied vocabulary and writing styles.',\n",
       " 'Word embeddings improve traditional TF-IDF by capturing semantic relationships.',\n",
       " 'Extractive summarization selects important sentences from the original text.',\n",
       " 'Smoke was seen pouring from the upper floors of the building.',\n",
       " 'The building houses regional government offices.',\n",
       " 'Italian police reported that there were no immediate reports of casualties.',\n",
       " \"Rescue workers attempted to clear the area in the city's financial district.\",\n",
       " 'The incident caused fears of a possible terrorist attack similar to September 11.',\n",
       " 'Police and ambulances responded quickly.',\n",
       " 'No terrorism link was confirmed.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sentences close to the semantic centroid are selected as summaries, improving coherence and relevance.Word embeddings allow semantic comparison between sentences beyond surface word matching. Emergency services rushed to the scene and investigations were initiated.Witnesses reported hearing a loud explosion when a small aircraft struck a 30-story office building near Milan’s central train station. Recent approaches utilize word embeddings to capture semantic similarity between words and sentences.Centroid-based summarization represents documents using vector representations. Authorities stated that the cause of the crash was under investigation.Italian authorities confirmed that a small airplane accidentally crashed into an office building in Milan. Firefighters managed to control the fire while emergency responders evacuated nearby areas.Automatic text summarization aims to reduce a document into a shorter version while preserving the most important information. A small airplane crashed into a government building in the heart of Milan, setting the top floors on fire. Combining centroid-based methods with embeddings enhances summarization performance, especially for documents with varied vocabulary and writing styles. Word embeddings improve traditional TF-IDF by capturing semantic relationships. Extractive summarization selects important sentences from the original text. Smoke was seen pouring from the upper floors of the building. The building houses regional government offices. Italian police reported that there were no immediate reports of casualties. Rescue workers attempted to clear the area in the city's financial district. The incident caused fears of a possible terrorist attack similar to September 11. Police and ambulances responded quickly. No terrorism link was confirmed.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1814"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
